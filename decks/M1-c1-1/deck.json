[
  { "term": "Learning (operational)", "def": "Optimization over a restricted hypothesis space to reduce loss on observed data. Axiom: learning drifts toward consistency, not truth." },
  { "term": "Learning as structured search", "def": "Learning viewed as search through a model space guided by feedback (loss) and constrained by representation. Axiom: structure determines what can be found." },
  { "term": "Hypothesis space (H)", "def": "The set of models the learner is allowed to consider. Axiom: H is your universe of possible explanations." },
  { "term": "Inductive bias", "def": "Assumptions that make some hypotheses more likely than others (architecture, priors, regularization). Axiom: no bias, no generalization." },
  { "term": "Constraint", "def": "A restriction that shrinks the effective search space (explicit rules, penalties, limited features). Axiom: constraints trade flexibility for stability." },
  { "term": "Projection (learning)", "def": "Mapping an unknown world onto a limited model class and finite data. Axiom: every model is a shadow of a larger reality." },

  { "term": "Training error", "def": "Loss computed on the training set. Axiom: low training error is necessary but not sufficient." },
  { "term": "Test error", "def": "Loss computed on unseen data from the same process. Axiom: test error is what you actually care about." },
  { "term": "Generalization", "def": "Performance on unseen samples drawn from the same underlying distribution. Axiom: the goal is future behavior, not past perfection." },
  { "term": "IID assumption", "def": "Training and test examples are independent and identically distributed samples. Axiom: generalization requires stable sampling assumptions." },

  { "term": "Overfitting", "def": "Fitting noise/idiosyncrasies so test performance worsens. Axiom: memorization can impersonate learning." },
  { "term": "Underfitting", "def": "Model too constrained to capture signal, yielding high error even on train. Axiom: too-simple maps miss real terrain." },
  { "term": "Capacity", "def": "A model class’s ability to represent many functions (degrees of freedom). Axiom: capacity is expressive power." },
  { "term": "Model complexity", "def": "Effective flexibility of the hypothesis class (not just parameter count). Axiom: complexity is the ability to fit varied patterns." },

  { "term": "Bias", "def": "Systematic error from restrictive assumptions or wrong model class. Axiom: bias is the price of structure." },
  { "term": "Variance", "def": "Sensitivity of learned model to dataset fluctuations (sampling noise). Axiom: variance is the price of flexibility." },
  { "term": "Bias–variance tradeoff", "def": "Balancing systematic error vs sensitivity to noise by choosing model complexity. Axiom: you can’t minimize both for free." },
  { "term": "Noise", "def": "Unpredictable variation in observations/labels not explained by features. Axiom: noise shifts likelihoods rather than breaking logic." },

  { "term": "Loss function", "def": "A scalar objective measuring prediction quality (often with regularization). Axiom: you get what you optimize." },
  { "term": "Objective function", "def": "Loss plus any penalties/constraints defining what ‘good’ means for training. Axiom: the objective defines the game." },
  { "term": "Regularization", "def": "Penalty/constraint discouraging complexity to improve generalization (e.g., L2). Axiom: prefer simpler explanations inside H." },
  { "term": "L2 regularization (weight decay)", "def": "Penalizes squared weights to keep parameters small and smooth solutions. Axiom: small weights tend to generalize better." },
  { "term": "L1 regularization", "def": "Penalizes absolute weights, encouraging sparsity. Axiom: fewer active features can reduce overfit." },

  { "term": "Gradient", "def": "Direction of steepest increase of a function; negative gradient points to steepest descent. Axiom: local slope guides local change." },
  { "term": "Gradient descent", "def": "Iterative update w ← w − η∇L(w) to reduce loss. Axiom: learning is hill-climbing in reverse." },
  { "term": "Stochastic gradient descent (SGD)", "def": "Gradient descent using noisy minibatch estimates of ∇L. Axiom: noise can be a feature, not a bug." },
  { "term": "Learning rate (η)", "def": "Step size controlling update magnitude and stability. Axiom: too big diverges; too small crawls." },
  { "term": "Loss landscape", "def": "Loss as a function over parameters, forming valleys/ridges/saddles. Axiom: training is navigation through geometry." },
  { "term": "Local minimum", "def": "A point where small moves increase loss though better points may exist elsewhere. Axiom: local geometry can trap you." },

  { "term": "Deduction (set logic)", "def": "Reasoning in/out with strict consistency; contradictions are fatal. Axiom: sets snap, they don’t bend." },
  { "term": "Probability (measure)", "def": "Reasoning by mass/likelihood; noise shifts weights instead of collapsing truth-values. Axiom: measures degrade gracefully." },
  { "term": "Graceful degradation", "def": "Performance declines smoothly as noise rises rather than collapsing. Axiom: likelihood softens contradiction." },
  { "term": "Compressibility view of learning", "def": "Prefer models/splits that encode labels with fewer bits given features. Axiom: shorter descriptions are favored." },

  { "term": "Entropy (Shannon)", "def": "Expected surprise: H(Y)=−∑ p(y)log p(y), measuring label uncertainty. Axiom: disorder is uncertainty." },
  { "term": "Conditional entropy", "def": "Remaining uncertainty in Y after observing X: H(Y|X). Axiom: conditioning reduces surprise." },
  { "term": "Information gain", "def": "Expected reduction in entropy from splitting on a feature. Axiom: good questions reduce uncertainty." },
  { "term": "Mutual information", "def": "Shared information between X and Y; reduction in uncertainty of one given the other. Axiom: dependence is predictability." },
  { "term": "Cross-entropy loss", "def": "Measures mismatch between predicted probabilities and true labels. Axiom: punish confident wrong answers." },

  { "term": "Decision tree", "def": "A model that predicts by recursively splitting feature space. Axiom: trees organize distinctions." },
  { "term": "Split", "def": "A decision rule that partitions examples into groups. Axiom: a split is a question." },
  { "term": "Impurity", "def": "How mixed the labels are in a node (e.g., entropy, Gini). Axiom: pure nodes are easy to describe." },
  { "term": "Gini impurity", "def": "Impurity measure: 1−∑ p(y)^2, often used in CART. Axiom: lower impurity means cleaner separation." },

  { "term": "Version space", "def": "Set of hypotheses in H consistent with observed training data in the idealized noiseless case. Axiom: data eliminates hypotheses." },
  { "term": "Underdetermination", "def": "Many hypotheses can fit the same finite data. Axiom: data rarely pins down the world uniquely." },
  { "term": "Occam bias", "def": "Preference for simpler hypotheses among those that fit. Axiom: simplest survivor wins inside your assumptions." },

  { "term": "LMS (Least Mean Squares)", "def": "Incremental method minimizing mean squared error using gradient steps. Axiom: adjust weights in proportion to error." },
  { "term": "MSE (mean squared error)", "def": "Average of squared prediction errors; smooth and differentiable. Axiom: square errors to heavily penalize large misses." },

  { "term": "Reinforcement learning (RL)", "def": "Learning by interacting with an environment to maximize cumulative reward. Axiom: goals are defined by reward." },
  { "term": "State", "def": "Representation containing enough information to predict future evolution given actions. Axiom: state is a compression of history." },
  { "term": "Action", "def": "A choice made by an agent that influences transitions. Axiom: actions steer trajectories." },
  { "term": "Transition", "def": "Dynamics mapping (state, action) → next state. Axiom: dynamics are the world-model." },
  { "term": "Trajectory", "def": "Sequence of states over time under actions and dynamics. Axiom: behavior is a path in state-space." },
  { "term": "Reward", "def": "Scalar feedback signal defining the objective in RL. Axiom: reward assigns meaning to outcomes." },
  { "term": "Policy", "def": "Mapping from states to actions (or distributions). Axiom: policy is behavior." },
  { "term": "Value function", "def": "Expected future return from a state (or state-action) under a policy. Axiom: value is discounted destiny." },
  { "term": "Discount factor (γ)", "def": "Weights future rewards vs immediate ones, 0≤γ<1. Axiom: patience is a parameter." },

  { "term": "Temporal Difference (TD) learning", "def": "Update value estimates using error between successive predictions (bootstrapping). Axiom: learn from prediction-to-prediction surprise." },
  { "term": "TD error (δ)", "def": "δ = r + γV(s') − V(s), the surprise driving TD updates. Axiom: δ is the learning signal." },
  { "term": "Bootstrapping", "def": "Updating estimates using other learned estimates (e.g., V(s') updates V(s)). Axiom: the learner teaches itself." },

  { "term": "Incompleteness (Gödel lens)", "def": "In expressive formal systems, some true statements are unprovable within the system. Axiom: no single formal map captures all truths." },
  { "term": "Consistency (system property)", "def": "A formal system does not derive contradictions. Axiom: consistency is survival for formal worlds." }
]
